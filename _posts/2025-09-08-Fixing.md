---
title: "Fixing Data That Hurts Performance: Cascading LLMs to Relabel Hard Negatives for Robust Information Retrieval"
author: seokgi
date: 2025-09-08
categories: [Paper]
tags: [LLM, DataAug, Hard Negative Sampling]
pin: true
math: true
---
Written by. Nandan Thakur, Crystina Zhang

## 1. 연구 배경

- **Information Retrieval** 시스템의 성능은 학습 데이터 품질에 크게 의존함.
- 특히 **hard negatives**의 잘못된 라벨링이 모델의 성능 저하를 초래함.
    - 예: MS MARCO에서는 최대 56%의 쿼리-패시지 쌍이 잘못된 부정 라벨 포함.
        
        ![image.png](https://seokilee0412.github.io/assets/img/Fixing/image.png)
        
- 기존 학습 데이터셋에는 잘못된 라벨이 많아, 검색 모델이 혼동하는 문제가 발생.

![image.png](https://seokilee0412.github.io/assets/img/Fixing/image1.png)

---

## 2. 문제 정의

- 학습 데이터의 hard negatives가 제대로 정의되지 않으면, 모델은 False Negative를 정답처럼 학습하게 됨.
- 이는 특히 **dense retrieval** 모델(BERT, bi-encoder 기반 모델 등)에서 크리티컬하게 작용.
- 따라서 **hard negatives의 라벨링 오류를 relabeling**하는 방법론이 필요.

---

## 3. 제안 방법: Cascading LLMs
”Cascading LLMs”라는 새로운 방법을 제안함.

![image.png](https://seokilee0412.github.io/assets/img/Fixing/image2.png)

> 이는 LLM을 단계적으로 활용하여 잘못된 hard negatives를 교정하는 과정.
False hard negative를 **GPT-4o-mini → GPT-4o** 두 단계 LLM을 활용하여 재레이블링을 통해 성능을 끌어올리는 **RLHN** (ReLabeling Hard Negatives) 기법을 제안
> 

LLM을 이용해 candidate negative들을 점검하고, False Negatives를 걸러냄.

1. 쿼리 + 정답 + 최대 25개의 hard negative 입력
2. GPT-4o-mini가 “이 중 false negative인 것 있음?” 판단
3. **있으면**, GPT-4o가 다시 판단하여 실제로 false negative인지 재검증
이 과정에서 **문맥 내 의미 연관성을 고려** (GPT-4o-mini, GPT-4o 동일):
- 주어진 질문(question), 정답 문서(ground_truth), 그리고 관련없다고 분류된 문서들(documents)을 입력.
- LLM은 먼저 관련성 여부를 판단하고(<thinking>), 관련이 있다고 판단하면 정답 문서와 비교해 선호 여부를 결정(<preference>).
- 마지막으로 관련 자료들 중 정답 문서보다 나은 또는 동등한 문서와, 관련 있으나 덜 선호되는 문서들을 분류(<verdict>)
4. 최종 결과에 따라 hard negative를 아래 방식 중 하나로 처리:
    | 처리 방식 | 설명 |
    | --- | --- |
    | `Remove` | 해당 쿼리 전체 샘플 제거 |
    | `HN Remove` | 해당 쿼리의 hard negative 중 false만 제거 |
    | `RLHN` | false negative를 positive(정답)으로 재레이블링 ← 이 방법이 가장 효과 좋음 |
    - 프롬프트
        
        ![image.png](https://seokilee0412.github.io/assets/img/Fixing/image3.png)
        

---

## 4. 실험

- **데이터셋**: 대규모 오픈 도메인 QA 및 IR 데이터셋 활용.
- **모델**: Dense Retriever (DPR, Contriever 등) + LLM 기반 re-labeling.
- **결과**:
    - 재라벨링 후 학습한 모델이 baseline 대비 **검색 정확도(Recall@k, MRR 등)에서 유의미한 향상**을 보임.
    - 특히 noisy negatives가 많은 데이터셋일수록 성능 개선 폭이 큼.
    - LLM cascade는 단일 LLM 사용보다 더 안정적인 라벨링 품질을 제공.

### 4.1 성능 결과

- **BEIR 평균 nDCG@10 향상:**
    
    ![image.png](https://seokilee0412.github.io/assets/img/Fixing/image4.png)
    
    - BEIR은 다양한 도메인(분야)에 걸친 16개 데이터셋으로 구성된 정보 검색 평가 세트
    - 모델들의 전반적인 리트리버 성능(nDCG@10)을 측정
        - 7개의 OOD(Out-Of-Domain) 데이터셋도 포함
    - E5(base), Qwen2.5-7B 모두 RLHN일 때 좋은 성능
- **AIR-BENCH 평균 성능 향상:**
    
    ![image.png](https://seokilee0412.github.io/assets/img/Fixing/image5.png)
    
    - AIR-BENCH는 상대적으로 도메인 특화된 5개 전문 분야(Arxiv, Finance, Healthcare, Law, News)를 대상
        - 법률, 헬스케어 등 도메인에 강한 성능
- **Reranker 성능도 향상:**
    
    ![image.png](https://seokilee0412.github.io/assets/img/Fixing/image6.png)
    
    - Qwen2.5-3B로 실험, RLHN Stage 2 적용 시 평균 0.8포인트 향상

### 4.2 **Pruning 실험**

![image.png](https://seokilee0412.github.io/assets/img/Fixing/image7.png)

- BGE 데이터셋에서 8**개 데이터셋 제거 → 성능 향상**
    - 1.6M → 680K 쌍으로 축소되었지만 nDCG@10 증가
    - ELI5 제거 시 평균 성능 0.519 → 0.525

### 4.3 **휴먼 밸리데이션**

- 670 쌍의 쿼리–hard negative에 대해 휴먼 평가 실시
- **Cohen’s Kappa**:
    - GPT-4o-mini: 0.32
    - GPT-4o: **0.39** (사람과 더 높은 일치)

---

## 5. 기여점

1. **데이터 품질 문제에 집중**: 단순히 더 큰 모델을 학습하는 것이 아니라, 학습 데이터의 hard negatives 오류를 수정하는 새로운 관점 제시.
2. **LLM 활용 방식 제안**: LLM을 “검색 모델 학습을 위한 데이터 개선 도구”로 사용한 사례.
3. **성능 검증**: 다양한 데이터셋과 모델에서 일관되게 성능 향상을 입증.

---

## 6. 한계 및 향후 연구

- LLM을 활용한 재라벨링은 **비용이 크고 속도가 느림** → 대규모 데이터셋에 적용하기에는 부담.
- LLM 판단이 항상 완벽하지 않음 → 잘못된 relabeling 위험 존재.
- 향후에는 **자동화된 cascade 최적화**, **휴리스틱과 결합된 효율적 방법** 연구 필요.